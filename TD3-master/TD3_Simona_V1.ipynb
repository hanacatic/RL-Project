{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TD3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python main.py \\\n",
    "--policy \"TD3\" \\\n",
    "--env \"MountainCar-v0\" \\\n",
    "-- seed $i \\\n",
    "--start_timesteps 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "# TD3\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Main\n",
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import utils\n",
    "#import TD3\n",
    "import OurDDPG\n",
    "import DDPG\n",
    "\n",
    "# Visualization\n",
    "import gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TD3 FILE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Implementation of Twin Delayed Deep Deterministic Policy Gradients (TD3)\n",
    "# Paper: https://arxiv.org/abs/1802.09477\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "\tdef __init__(self, state_dim, action_dim, max_action):\n",
    "\t\tsuper(Actor, self).__init__()\n",
    "\n",
    "\t\tself.l1 = nn.Linear(state_dim, 256)\n",
    "\t\tself.l2 = nn.Linear(256, 256)\n",
    "\t\tself.l3 = nn.Linear(256, action_dim)\n",
    "\t\t\n",
    "\t\tself.max_action = max_action\n",
    "\t\t\n",
    "\n",
    "\tdef forward(self, state):\n",
    "\t\ta = F.relu(self.l1(state))\n",
    "\t\ta = F.relu(self.l2(a))\n",
    "\t\treturn self.max_action * torch.tanh(self.l3(a))\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\tdef __init__(self, state_dim, action_dim):\n",
    "\t\tsuper(Critic, self).__init__()\n",
    "\n",
    "\t\t# Q1 architecture\n",
    "\t\tself.l1 = nn.Linear(state_dim + action_dim, 256)\n",
    "\t\tself.l2 = nn.Linear(256, 256)\n",
    "\t\tself.l3 = nn.Linear(256, 1)\n",
    "\n",
    "\t\t# Q2 architecture\n",
    "\t\tself.l4 = nn.Linear(state_dim + action_dim, 256)\n",
    "\t\tself.l5 = nn.Linear(256, 256)\n",
    "\t\tself.l6 = nn.Linear(256, 1)\n",
    "\n",
    "\n",
    "\tdef forward(self, state, action):\n",
    "\t\tsa = torch.cat([state, action], 1)\n",
    "\n",
    "\t\tq1 = F.relu(self.l1(sa))\n",
    "\t\tq1 = F.relu(self.l2(q1))\n",
    "\t\tq1 = self.l3(q1)\n",
    "\n",
    "\t\tq2 = F.relu(self.l4(sa))\n",
    "\t\tq2 = F.relu(self.l5(q2))\n",
    "\t\tq2 = self.l6(q2)\n",
    "\t\treturn q1, q2\n",
    "\n",
    "\n",
    "\tdef Q1(self, state, action):\n",
    "\t\tsa = torch.cat([state, action], 1)\n",
    "\n",
    "\t\tq1 = F.relu(self.l1(sa))\n",
    "\t\tq1 = F.relu(self.l2(q1))\n",
    "\t\tq1 = self.l3(q1)\n",
    "\t\treturn q1\n",
    "\n",
    "\n",
    "class TD3(object):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tstate_dim,\n",
    "\t\taction_dim,\n",
    "\t\tmax_action,\n",
    "\t\tdiscount=0.99,\n",
    "\t\ttau=0.005,\n",
    "\t\tpolicy_noise=0.2,\n",
    "\t\tnoise_clip=0.5,\n",
    "\t\tpolicy_freq=2\n",
    "\t):\n",
    "\n",
    "\t\tself.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "\t\tself.actor_target = copy.deepcopy(self.actor)\n",
    "\t\tself.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=3e-4)\n",
    "\n",
    "\t\tself.critic = Critic(state_dim, action_dim).to(device)\n",
    "\t\tself.critic_target = copy.deepcopy(self.critic)\n",
    "\t\tself.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=3e-4)\n",
    "\n",
    "\t\tself.max_action = max_action\n",
    "\t\tself.discount = discount\n",
    "\t\tself.tau = tau\n",
    "\t\tself.policy_noise = policy_noise\n",
    "\t\tself.noise_clip = noise_clip\n",
    "\t\tself.policy_freq = policy_freq\n",
    "\n",
    "\t\tself.total_it = 0\n",
    "\n",
    "\n",
    "\tdef select_action(self, state):\n",
    "\t\tstate = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
    "\t\treturn self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "\n",
    "\tdef train(self, replay_buffer, batch_size=256):\n",
    "\t\tself.total_it += 1\n",
    "\n",
    "\t\t# Sample replay buffer \n",
    "\t\tstate, action, next_state, reward, not_done = replay_buffer.sample(batch_size)\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# Select action according to policy and add clipped noise\n",
    "\t\t\tnoise = (\n",
    "\t\t\t\ttorch.randn_like(action) * self.policy_noise\n",
    "\t\t\t).clamp(-self.noise_clip, self.noise_clip)\n",
    "\t\t\t\n",
    "\t\t\tnext_action = (\n",
    "\t\t\t\tself.actor_target(next_state) + noise\n",
    "\t\t\t).clamp(-self.max_action, self.max_action)\n",
    "\n",
    "\t\t\t# Compute the target Q value\n",
    "\t\t\ttarget_Q1, target_Q2 = self.critic_target(next_state, next_action)\n",
    "\t\t\ttarget_Q = torch.min(target_Q1, target_Q2)\n",
    "\t\t\ttarget_Q = reward + not_done * self.discount * target_Q\n",
    "\n",
    "\t\t# Get current Q estimates\n",
    "\t\tcurrent_Q1, current_Q2 = self.critic(state, action)\n",
    "\n",
    "\t\t# Compute critic loss\n",
    "\t\tcritic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(current_Q2, target_Q)\n",
    "\n",
    "\t\t# Optimize the critic\n",
    "\t\tself.critic_optimizer.zero_grad()\n",
    "\t\tcritic_loss.backward()\n",
    "\t\tself.critic_optimizer.step()\n",
    "\n",
    "\t\t# Delayed policy updates\n",
    "\t\tif self.total_it % self.policy_freq == 0:\n",
    "\n",
    "\t\t\t# Compute actor losse\n",
    "\t\t\tactor_loss = -self.critic.Q1(state, self.actor(state)).mean()\n",
    "\t\t\t\n",
    "\t\t\t# Optimize the actor \n",
    "\t\t\tself.actor_optimizer.zero_grad()\n",
    "\t\t\tactor_loss.backward()\n",
    "\t\t\tself.actor_optimizer.step()\n",
    "\n",
    "\t\t\t# Update the frozen target models\n",
    "\t\t\tfor param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "\t\t\t\ttarget_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "\t\t\tfor param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "\t\t\t\ttarget_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "\n",
    "\tdef save(self, filename):\n",
    "\t\ttorch.save(self.critic.state_dict(), filename + \"_critic\")\n",
    "\t\ttorch.save(self.critic_optimizer.state_dict(), filename + \"_critic_optimizer\")\n",
    "\t\t\n",
    "\t\ttorch.save(self.actor.state_dict(), filename + \"_actor\")\n",
    "\t\ttorch.save(self.actor_optimizer.state_dict(), filename + \"_actor_optimizer\")\n",
    "\n",
    "\n",
    "\tdef load(self, filename):\n",
    "\t\tself.critic.load_state_dict(torch.load(filename + \"_critic\"))\n",
    "\t\tself.critic_optimizer.load_state_dict(torch.load(filename + \"_critic_optimizer\"))\n",
    "\t\tself.critic_target = copy.deepcopy(self.critic)\n",
    "\n",
    "\t\tself.actor.load_state_dict(torch.load(filename + \"_actor\"))\n",
    "\t\tself.actor_optimizer.load_state_dict(torch.load(filename + \"_actor_optimizer\"))\n",
    "\t\tself.actor_target = copy.deepcopy(self.actor)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters settings\n",
    "\n",
    "class Args:\n",
    "    policy = \"TD3\"                  # Policy name (TD3, DDPG, or OurDDPG)\n",
    "    env = \"MountainCarContinuous-v0\"          # OpenAI gym environment name\n",
    "    seed = 0                        # Sets Gym, PyTorch, and Numpy seeds\n",
    "    start_timesteps = 25000         # Time steps initial random policy is used\n",
    "    eval_freq = 5000                # How often (time steps) we evaluate\n",
    "    max_timesteps = 150000         # Max time steps to run environment\n",
    "    expl_noise = 2               # Std of Gaussian exploration noise\n",
    "    batch_size = 256                # Batch size for both actor and critic\n",
    "    discount = 0.99                 # Discount factor\n",
    "    tau = 0.05                     # Target network update rate\n",
    "    policy_noise = 0.2              # Noise added to target policy during critic update\n",
    "    noise_clip = 0.5                # Range to clip target policy noise\n",
    "    policy_freq = 2                 # Frequency of delayed policy updates\n",
    "    save_model = False              # Save model and optimizer parameters\n",
    "    load_model = \"\"                 # Model load file name, \"\" doesn't load, \"default\" uses file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Policy: TD3, Env: MountainCarContinuous-v0, Seed: 0\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.277\n",
      "---------------------------------------\n",
      "Total T: 999 Episode Num: 1 Episode T: 999 Reward: -32.504\n",
      "Total T: 1998 Episode Num: 2 Episode T: 999 Reward: -35.036\n",
      "Total T: 2997 Episode Num: 3 Episode T: 999 Reward: -32.692\n",
      "Total T: 3996 Episode Num: 4 Episode T: 999 Reward: -32.465\n",
      "Total T: 4995 Episode Num: 5 Episode T: 999 Reward: -35.142\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.277\n",
      "---------------------------------------\n",
      "Total T: 5994 Episode Num: 6 Episode T: 999 Reward: -32.234\n",
      "Total T: 6993 Episode Num: 7 Episode T: 999 Reward: -34.059\n",
      "Total T: 7992 Episode Num: 8 Episode T: 999 Reward: -33.792\n",
      "Total T: 8991 Episode Num: 9 Episode T: 999 Reward: -33.278\n",
      "Total T: 9990 Episode Num: 10 Episode T: 999 Reward: -32.696\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.277\n",
      "---------------------------------------\n",
      "Total T: 10989 Episode Num: 11 Episode T: 999 Reward: -32.580\n",
      "Total T: 11988 Episode Num: 12 Episode T: 999 Reward: -33.955\n",
      "Total T: 12987 Episode Num: 13 Episode T: 999 Reward: -33.182\n",
      "Total T: 13986 Episode Num: 14 Episode T: 999 Reward: -33.186\n",
      "Total T: 14985 Episode Num: 15 Episode T: 999 Reward: -32.310\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.277\n",
      "---------------------------------------\n",
      "Total T: 15984 Episode Num: 16 Episode T: 999 Reward: -32.807\n",
      "Total T: 16983 Episode Num: 17 Episode T: 999 Reward: -31.836\n",
      "Total T: 17982 Episode Num: 18 Episode T: 999 Reward: -33.139\n",
      "Total T: 18981 Episode Num: 19 Episode T: 999 Reward: -32.588\n",
      "Total T: 19980 Episode Num: 20 Episode T: 999 Reward: -32.118\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.277\n",
      "---------------------------------------\n",
      "Total T: 20979 Episode Num: 21 Episode T: 999 Reward: -32.293\n",
      "Total T: 21978 Episode Num: 22 Episode T: 999 Reward: -32.756\n",
      "Total T: 22977 Episode Num: 23 Episode T: 999 Reward: -32.745\n",
      "Total T: 23976 Episode Num: 24 Episode T: 999 Reward: -31.752\n",
      "Total T: 24975 Episode Num: 25 Episode T: 999 Reward: -33.952\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.277\n",
      "---------------------------------------\n",
      "Total T: 25974 Episode Num: 26 Episode T: 999 Reward: -72.157\n",
      "Total T: 26973 Episode Num: 27 Episode T: 999 Reward: -72.361\n",
      "Total T: 27972 Episode Num: 28 Episode T: 999 Reward: -73.847\n",
      "Total T: 28971 Episode Num: 29 Episode T: 999 Reward: -72.866\n",
      "Total T: 29970 Episode Num: 30 Episode T: 999 Reward: -72.824\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.004\n",
      "---------------------------------------\n",
      "Total T: 30969 Episode Num: 31 Episode T: 999 Reward: -72.444\n",
      "Total T: 31968 Episode Num: 32 Episode T: 999 Reward: -73.368\n",
      "Total T: 32967 Episode Num: 33 Episode T: 999 Reward: -75.016\n",
      "Total T: 33966 Episode Num: 34 Episode T: 999 Reward: -74.998\n",
      "Total T: 34965 Episode Num: 35 Episode T: 999 Reward: -72.856\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.029\n",
      "---------------------------------------\n",
      "Total T: 35964 Episode Num: 36 Episode T: 999 Reward: -75.559\n",
      "Total T: 36963 Episode Num: 37 Episode T: 999 Reward: -73.821\n",
      "Total T: 37962 Episode Num: 38 Episode T: 999 Reward: -72.991\n",
      "Total T: 38961 Episode Num: 39 Episode T: 999 Reward: -73.790\n",
      "Total T: 39960 Episode Num: 40 Episode T: 999 Reward: -71.657\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.005\n",
      "---------------------------------------\n",
      "Total T: 40959 Episode Num: 41 Episode T: 999 Reward: -76.096\n",
      "Total T: 41958 Episode Num: 42 Episode T: 999 Reward: -75.694\n",
      "Total T: 42957 Episode Num: 43 Episode T: 999 Reward: -73.420\n",
      "Total T: 43956 Episode Num: 44 Episode T: 999 Reward: -73.605\n",
      "Total T: 44955 Episode Num: 45 Episode T: 999 Reward: -72.521\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.035\n",
      "---------------------------------------\n",
      "Total T: 45954 Episode Num: 46 Episode T: 999 Reward: -75.328\n",
      "Total T: 46953 Episode Num: 47 Episode T: 999 Reward: -73.012\n",
      "Total T: 47952 Episode Num: 48 Episode T: 999 Reward: -75.556\n",
      "Total T: 48951 Episode Num: 49 Episode T: 999 Reward: -74.742\n",
      "Total T: 49950 Episode Num: 50 Episode T: 999 Reward: -73.264\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.009\n",
      "---------------------------------------\n",
      "Total T: 50949 Episode Num: 51 Episode T: 999 Reward: -74.777\n",
      "Total T: 51948 Episode Num: 52 Episode T: 999 Reward: -74.532\n",
      "Total T: 52675 Episode Num: 53 Episode T: 727 Reward: 45.159\n",
      "Total T: 53674 Episode Num: 54 Episode T: 999 Reward: -72.920\n",
      "Total T: 54462 Episode Num: 55 Episode T: 788 Reward: 41.346\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -0.043\n",
      "---------------------------------------\n",
      "Total T: 55461 Episode Num: 56 Episode T: 999 Reward: -71.839\n",
      "Total T: 56460 Episode Num: 57 Episode T: 999 Reward: -74.647\n",
      "Total T: 57459 Episode Num: 58 Episode T: 999 Reward: -73.325\n",
      "Total T: 58458 Episode Num: 59 Episode T: 999 Reward: -74.719\n",
      "Total T: 59457 Episode Num: 60 Episode T: 999 Reward: -76.660\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: -2.875\n",
      "---------------------------------------\n",
      "Total T: 60233 Episode Num: 61 Episode T: 776 Reward: 43.966\n",
      "Total T: 61232 Episode Num: 62 Episode T: 999 Reward: -73.349\n",
      "Total T: 61680 Episode Num: 63 Episode T: 448 Reward: 65.675\n",
      "Total T: 62153 Episode Num: 64 Episode T: 473 Reward: 64.128\n",
      "Total T: 63152 Episode Num: 65 Episode T: 999 Reward: -73.757\n",
      "Total T: 63513 Episode Num: 66 Episode T: 361 Reward: 72.381\n",
      "Total T: 64074 Episode Num: 67 Episode T: 561 Reward: 59.199\n",
      "Total T: 64657 Episode Num: 68 Episode T: 583 Reward: 54.786\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 86.642\n",
      "---------------------------------------\n",
      "Total T: 65044 Episode Num: 69 Episode T: 387 Reward: 70.298\n",
      "Total T: 65341 Episode Num: 70 Episode T: 297 Reward: 76.821\n",
      "Total T: 65761 Episode Num: 71 Episode T: 420 Reward: 69.179\n",
      "Total T: 66089 Episode Num: 72 Episode T: 328 Reward: 74.677\n",
      "Total T: 66477 Episode Num: 73 Episode T: 388 Reward: 70.891\n",
      "Total T: 66640 Episode Num: 74 Episode T: 163 Reward: 87.675\n",
      "Total T: 66862 Episode Num: 75 Episode T: 222 Reward: 82.761\n",
      "Total T: 67087 Episode Num: 76 Episode T: 225 Reward: 82.767\n",
      "Total T: 67323 Episode Num: 77 Episode T: 236 Reward: 82.086\n",
      "Total T: 67480 Episode Num: 78 Episode T: 157 Reward: 87.528\n",
      "Total T: 67720 Episode Num: 79 Episode T: 240 Reward: 81.741\n",
      "Total T: 67963 Episode Num: 80 Episode T: 243 Reward: 80.522\n",
      "Total T: 68141 Episode Num: 81 Episode T: 178 Reward: 86.191\n",
      "Total T: 68374 Episode Num: 82 Episode T: 233 Reward: 82.810\n",
      "Total T: 68618 Episode Num: 83 Episode T: 244 Reward: 81.815\n",
      "Total T: 68786 Episode Num: 84 Episode T: 168 Reward: 87.464\n",
      "Total T: 69023 Episode Num: 85 Episode T: 237 Reward: 82.176\n",
      "Total T: 69193 Episode Num: 86 Episode T: 170 Reward: 86.611\n",
      "Total T: 69358 Episode Num: 87 Episode T: 165 Reward: 87.962\n",
      "Total T: 69524 Episode Num: 88 Episode T: 166 Reward: 86.187\n",
      "Total T: 69792 Episode Num: 89 Episode T: 268 Reward: 80.250\n",
      "Total T: 69956 Episode Num: 90 Episode T: 164 Reward: 87.488\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.563\n",
      "---------------------------------------\n",
      "Total T: 70125 Episode Num: 91 Episode T: 169 Reward: 86.881\n",
      "Total T: 70384 Episode Num: 92 Episode T: 259 Reward: 80.861\n",
      "Total T: 70683 Episode Num: 93 Episode T: 299 Reward: 78.249\n",
      "Total T: 70829 Episode Num: 94 Episode T: 146 Reward: 88.390\n",
      "Total T: 70985 Episode Num: 95 Episode T: 156 Reward: 88.300\n",
      "Total T: 71227 Episode Num: 96 Episode T: 242 Reward: 81.531\n",
      "Total T: 71520 Episode Num: 97 Episode T: 293 Reward: 78.073\n",
      "Total T: 71675 Episode Num: 98 Episode T: 155 Reward: 87.855\n",
      "Total T: 71832 Episode Num: 99 Episode T: 157 Reward: 87.488\n",
      "Total T: 72058 Episode Num: 100 Episode T: 226 Reward: 82.079\n",
      "Total T: 72282 Episode Num: 101 Episode T: 224 Reward: 83.119\n",
      "Total T: 72510 Episode Num: 102 Episode T: 228 Reward: 83.091\n",
      "Total T: 72667 Episode Num: 103 Episode T: 157 Reward: 87.467\n",
      "Total T: 72904 Episode Num: 104 Episode T: 237 Reward: 82.512\n",
      "Total T: 73056 Episode Num: 105 Episode T: 152 Reward: 88.106\n",
      "Total T: 73220 Episode Num: 106 Episode T: 164 Reward: 87.116\n",
      "Total T: 73380 Episode Num: 107 Episode T: 160 Reward: 87.458\n",
      "Total T: 73539 Episode Num: 108 Episode T: 159 Reward: 87.351\n",
      "Total T: 73731 Episode Num: 109 Episode T: 192 Reward: 85.216\n",
      "Total T: 73890 Episode Num: 110 Episode T: 159 Reward: 87.302\n",
      "Total T: 74059 Episode Num: 111 Episode T: 169 Reward: 87.460\n",
      "Total T: 74269 Episode Num: 112 Episode T: 210 Reward: 84.221\n",
      "Total T: 74433 Episode Num: 113 Episode T: 164 Reward: 86.871\n",
      "Total T: 74601 Episode Num: 114 Episode T: 168 Reward: 87.703\n",
      "Total T: 74830 Episode Num: 115 Episode T: 229 Reward: 82.588\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 92.728\n",
      "---------------------------------------\n",
      "Total T: 75165 Episode Num: 116 Episode T: 335 Reward: 74.939\n",
      "Total T: 75325 Episode Num: 117 Episode T: 160 Reward: 87.809\n",
      "Total T: 75508 Episode Num: 118 Episode T: 183 Reward: 86.046\n",
      "Total T: 75735 Episode Num: 119 Episode T: 227 Reward: 82.536\n",
      "Total T: 75924 Episode Num: 120 Episode T: 189 Reward: 85.173\n",
      "Total T: 76049 Episode Num: 121 Episode T: 125 Reward: 90.560\n",
      "Total T: 76287 Episode Num: 122 Episode T: 238 Reward: 81.558\n",
      "Total T: 76533 Episode Num: 123 Episode T: 246 Reward: 81.057\n",
      "Total T: 76723 Episode Num: 124 Episode T: 190 Reward: 85.723\n",
      "Total T: 76929 Episode Num: 125 Episode T: 206 Reward: 83.986\n",
      "Total T: 77132 Episode Num: 126 Episode T: 203 Reward: 84.491\n",
      "Total T: 77302 Episode Num: 127 Episode T: 170 Reward: 87.916\n",
      "Total T: 77498 Episode Num: 128 Episode T: 196 Reward: 84.912\n",
      "Total T: 77700 Episode Num: 129 Episode T: 202 Reward: 83.478\n",
      "Total T: 77850 Episode Num: 130 Episode T: 150 Reward: 88.303\n",
      "Total T: 78081 Episode Num: 131 Episode T: 231 Reward: 82.155\n",
      "Total T: 78240 Episode Num: 132 Episode T: 159 Reward: 88.052\n",
      "Total T: 78486 Episode Num: 133 Episode T: 246 Reward: 81.965\n",
      "Total T: 78712 Episode Num: 134 Episode T: 226 Reward: 83.128\n",
      "Total T: 78997 Episode Num: 135 Episode T: 285 Reward: 79.293\n",
      "Total T: 79292 Episode Num: 136 Episode T: 295 Reward: 77.875\n",
      "Total T: 79468 Episode Num: 137 Episode T: 176 Reward: 86.816\n",
      "Total T: 79713 Episode Num: 138 Episode T: 245 Reward: 82.197\n",
      "Total T: 79874 Episode Num: 139 Episode T: 161 Reward: 87.709\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.056\n",
      "---------------------------------------\n",
      "Total T: 80098 Episode Num: 140 Episode T: 224 Reward: 82.732\n",
      "Total T: 80248 Episode Num: 141 Episode T: 150 Reward: 87.961\n",
      "Total T: 80406 Episode Num: 142 Episode T: 158 Reward: 87.659\n",
      "Total T: 80649 Episode Num: 143 Episode T: 243 Reward: 79.779\n",
      "Total T: 80851 Episode Num: 144 Episode T: 202 Reward: 84.371\n",
      "Total T: 81011 Episode Num: 145 Episode T: 160 Reward: 87.059\n",
      "Total T: 81170 Episode Num: 146 Episode T: 159 Reward: 87.264\n",
      "Total T: 81370 Episode Num: 147 Episode T: 200 Reward: 83.887\n",
      "Total T: 81519 Episode Num: 148 Episode T: 149 Reward: 88.927\n",
      "Total T: 81725 Episode Num: 149 Episode T: 206 Reward: 84.549\n",
      "Total T: 81871 Episode Num: 150 Episode T: 146 Reward: 88.485\n",
      "Total T: 82062 Episode Num: 151 Episode T: 191 Reward: 85.671\n",
      "Total T: 82304 Episode Num: 152 Episode T: 242 Reward: 80.698\n",
      "Total T: 82518 Episode Num: 153 Episode T: 214 Reward: 83.939\n",
      "Total T: 82837 Episode Num: 154 Episode T: 319 Reward: 76.274\n",
      "Total T: 82997 Episode Num: 155 Episode T: 160 Reward: 87.303\n",
      "Total T: 83159 Episode Num: 156 Episode T: 162 Reward: 86.869\n",
      "Total T: 83387 Episode Num: 157 Episode T: 228 Reward: 82.388\n",
      "Total T: 83583 Episode Num: 158 Episode T: 196 Reward: 84.739\n",
      "Total T: 83737 Episode Num: 159 Episode T: 154 Reward: 87.360\n",
      "Total T: 83958 Episode Num: 160 Episode T: 221 Reward: 82.965\n",
      "Total T: 84105 Episode Num: 161 Episode T: 147 Reward: 88.556\n",
      "Total T: 84272 Episode Num: 162 Episode T: 167 Reward: 86.872\n",
      "Total T: 84508 Episode Num: 163 Episode T: 236 Reward: 81.571\n",
      "Total T: 84661 Episode Num: 164 Episode T: 153 Reward: 87.702\n",
      "Total T: 84815 Episode Num: 165 Episode T: 154 Reward: 89.058\n",
      "Total T: 84997 Episode Num: 166 Episode T: 182 Reward: 86.732\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.277\n",
      "---------------------------------------\n",
      "Total T: 85137 Episode Num: 167 Episode T: 140 Reward: 88.382\n",
      "Total T: 85294 Episode Num: 168 Episode T: 157 Reward: 88.769\n",
      "Total T: 85453 Episode Num: 169 Episode T: 159 Reward: 87.875\n",
      "Total T: 85673 Episode Num: 170 Episode T: 220 Reward: 84.118\n",
      "Total T: 85998 Episode Num: 171 Episode T: 325 Reward: 73.123\n",
      "Total T: 86150 Episode Num: 172 Episode T: 152 Reward: 87.274\n",
      "Total T: 86355 Episode Num: 173 Episode T: 205 Reward: 83.845\n",
      "Total T: 86628 Episode Num: 174 Episode T: 273 Reward: 78.837\n",
      "Total T: 86775 Episode Num: 175 Episode T: 147 Reward: 88.457\n",
      "Total T: 87081 Episode Num: 176 Episode T: 306 Reward: 77.096\n",
      "Total T: 87229 Episode Num: 177 Episode T: 148 Reward: 88.871\n",
      "Total T: 87388 Episode Num: 178 Episode T: 159 Reward: 87.843\n",
      "Total T: 87480 Episode Num: 179 Episode T: 92 Reward: 92.637\n",
      "Total T: 87710 Episode Num: 180 Episode T: 230 Reward: 82.725\n",
      "Total T: 87866 Episode Num: 181 Episode T: 156 Reward: 87.623\n",
      "Total T: 88099 Episode Num: 182 Episode T: 233 Reward: 82.379\n",
      "Total T: 88303 Episode Num: 183 Episode T: 204 Reward: 84.356\n",
      "Total T: 88551 Episode Num: 184 Episode T: 248 Reward: 81.195\n",
      "Total T: 88688 Episode Num: 185 Episode T: 137 Reward: 89.280\n",
      "Total T: 88903 Episode Num: 186 Episode T: 215 Reward: 83.350\n",
      "Total T: 89132 Episode Num: 187 Episode T: 229 Reward: 81.131\n",
      "Total T: 89299 Episode Num: 188 Episode T: 167 Reward: 87.292\n",
      "Total T: 89531 Episode Num: 189 Episode T: 232 Reward: 81.782\n",
      "Total T: 89766 Episode Num: 190 Episode T: 235 Reward: 81.194\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 92.976\n",
      "---------------------------------------\n",
      "Total T: 90090 Episode Num: 191 Episode T: 324 Reward: 75.294\n",
      "Total T: 90323 Episode Num: 192 Episode T: 233 Reward: 82.692\n",
      "Total T: 90484 Episode Num: 193 Episode T: 161 Reward: 87.403\n",
      "Total T: 90676 Episode Num: 194 Episode T: 192 Reward: 84.356\n",
      "Total T: 90832 Episode Num: 195 Episode T: 156 Reward: 88.095\n",
      "Total T: 91060 Episode Num: 196 Episode T: 228 Reward: 82.606\n",
      "Total T: 91251 Episode Num: 197 Episode T: 191 Reward: 84.825\n",
      "Total T: 91406 Episode Num: 198 Episode T: 155 Reward: 88.226\n",
      "Total T: 91573 Episode Num: 199 Episode T: 167 Reward: 86.887\n",
      "Total T: 91726 Episode Num: 200 Episode T: 153 Reward: 88.419\n",
      "Total T: 91932 Episode Num: 201 Episode T: 206 Reward: 84.400\n",
      "Total T: 92112 Episode Num: 202 Episode T: 180 Reward: 86.833\n",
      "Total T: 92358 Episode Num: 203 Episode T: 246 Reward: 80.634\n",
      "Total T: 92535 Episode Num: 204 Episode T: 177 Reward: 86.653\n",
      "Total T: 92689 Episode Num: 205 Episode T: 154 Reward: 88.329\n",
      "Total T: 92929 Episode Num: 206 Episode T: 240 Reward: 81.287\n",
      "Total T: 93086 Episode Num: 207 Episode T: 157 Reward: 87.906\n",
      "Total T: 93324 Episode Num: 208 Episode T: 238 Reward: 81.267\n",
      "Total T: 93483 Episode Num: 209 Episode T: 159 Reward: 87.800\n",
      "Total T: 93722 Episode Num: 210 Episode T: 239 Reward: 82.470\n",
      "Total T: 93906 Episode Num: 211 Episode T: 184 Reward: 85.913\n",
      "Total T: 94114 Episode Num: 212 Episode T: 208 Reward: 85.133\n",
      "Total T: 94315 Episode Num: 213 Episode T: 201 Reward: 84.862\n",
      "Total T: 94471 Episode Num: 214 Episode T: 156 Reward: 87.222\n",
      "Total T: 94684 Episode Num: 215 Episode T: 213 Reward: 82.807\n",
      "Total T: 94909 Episode Num: 216 Episode T: 225 Reward: 82.962\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.094\n",
      "---------------------------------------\n",
      "Total T: 95063 Episode Num: 217 Episode T: 154 Reward: 88.389\n",
      "Total T: 95303 Episode Num: 218 Episode T: 240 Reward: 82.167\n",
      "Total T: 95453 Episode Num: 219 Episode T: 150 Reward: 88.045\n",
      "Total T: 95621 Episode Num: 220 Episode T: 168 Reward: 87.257\n",
      "Total T: 95772 Episode Num: 221 Episode T: 151 Reward: 88.922\n",
      "Total T: 95909 Episode Num: 222 Episode T: 137 Reward: 89.677\n",
      "Total T: 96122 Episode Num: 223 Episode T: 213 Reward: 83.118\n",
      "Total T: 96306 Episode Num: 224 Episode T: 184 Reward: 84.895\n",
      "Total T: 96478 Episode Num: 225 Episode T: 172 Reward: 87.045\n",
      "Total T: 96636 Episode Num: 226 Episode T: 158 Reward: 87.602\n",
      "Total T: 96790 Episode Num: 227 Episode T: 154 Reward: 87.899\n",
      "Total T: 96937 Episode Num: 228 Episode T: 147 Reward: 88.467\n",
      "Total T: 97301 Episode Num: 229 Episode T: 364 Reward: 72.904\n",
      "Total T: 97535 Episode Num: 230 Episode T: 234 Reward: 82.486\n",
      "Total T: 97759 Episode Num: 231 Episode T: 224 Reward: 83.074\n",
      "Total T: 98005 Episode Num: 232 Episode T: 246 Reward: 81.519\n",
      "Total T: 98236 Episode Num: 233 Episode T: 231 Reward: 81.218\n",
      "Total T: 98382 Episode Num: 234 Episode T: 146 Reward: 87.792\n",
      "Total T: 98584 Episode Num: 235 Episode T: 202 Reward: 84.268\n",
      "Total T: 98803 Episode Num: 236 Episode T: 219 Reward: 83.398\n",
      "Total T: 98984 Episode Num: 237 Episode T: 181 Reward: 86.412\n",
      "Total T: 99131 Episode Num: 238 Episode T: 147 Reward: 88.793\n",
      "Total T: 99377 Episode Num: 239 Episode T: 246 Reward: 80.799\n",
      "Total T: 99546 Episode Num: 240 Episode T: 169 Reward: 87.470\n",
      "Total T: 99786 Episode Num: 241 Episode T: 240 Reward: 81.442\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 92.974\n",
      "---------------------------------------\n",
      "Total T: 100015 Episode Num: 242 Episode T: 229 Reward: 82.202\n",
      "Total T: 100180 Episode Num: 243 Episode T: 165 Reward: 87.076\n",
      "Total T: 100410 Episode Num: 244 Episode T: 230 Reward: 82.343\n",
      "Total T: 100558 Episode Num: 245 Episode T: 148 Reward: 88.677\n",
      "Total T: 100704 Episode Num: 246 Episode T: 146 Reward: 89.473\n",
      "Total T: 100872 Episode Num: 247 Episode T: 168 Reward: 87.126\n",
      "Total T: 100961 Episode Num: 248 Episode T: 89 Reward: 92.470\n",
      "Total T: 101190 Episode Num: 249 Episode T: 229 Reward: 82.365\n",
      "Total T: 101426 Episode Num: 250 Episode T: 236 Reward: 82.151\n",
      "Total T: 101645 Episode Num: 251 Episode T: 219 Reward: 82.726\n",
      "Total T: 101869 Episode Num: 252 Episode T: 224 Reward: 82.484\n",
      "Total T: 102225 Episode Num: 253 Episode T: 356 Reward: 72.616\n",
      "Total T: 102375 Episode Num: 254 Episode T: 150 Reward: 88.394\n",
      "Total T: 102527 Episode Num: 255 Episode T: 152 Reward: 88.126\n",
      "Total T: 102763 Episode Num: 256 Episode T: 236 Reward: 81.858\n",
      "Total T: 102909 Episode Num: 257 Episode T: 146 Reward: 88.225\n",
      "Total T: 103121 Episode Num: 258 Episode T: 212 Reward: 83.261\n",
      "Total T: 103345 Episode Num: 259 Episode T: 224 Reward: 83.018\n",
      "Total T: 103507 Episode Num: 260 Episode T: 162 Reward: 87.550\n",
      "Total T: 103743 Episode Num: 261 Episode T: 236 Reward: 82.553\n",
      "Total T: 103970 Episode Num: 262 Episode T: 227 Reward: 82.649\n",
      "Total T: 104130 Episode Num: 263 Episode T: 160 Reward: 87.344\n",
      "Total T: 104362 Episode Num: 264 Episode T: 232 Reward: 82.328\n",
      "Total T: 104508 Episode Num: 265 Episode T: 146 Reward: 88.621\n",
      "Total T: 104751 Episode Num: 266 Episode T: 243 Reward: 81.017\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.218\n",
      "---------------------------------------\n",
      "Total T: 105064 Episode Num: 267 Episode T: 313 Reward: 75.679\n",
      "Total T: 105479 Episode Num: 268 Episode T: 415 Reward: 69.599\n",
      "Total T: 105722 Episode Num: 269 Episode T: 243 Reward: 80.884\n",
      "Total T: 105939 Episode Num: 270 Episode T: 217 Reward: 83.437\n",
      "Total T: 106107 Episode Num: 271 Episode T: 168 Reward: 87.271\n",
      "Total T: 106266 Episode Num: 272 Episode T: 159 Reward: 88.003\n",
      "Total T: 106591 Episode Num: 273 Episode T: 325 Reward: 75.698\n",
      "Total T: 106918 Episode Num: 274 Episode T: 327 Reward: 74.922\n",
      "Total T: 107061 Episode Num: 275 Episode T: 143 Reward: 89.027\n",
      "Total T: 107217 Episode Num: 276 Episode T: 156 Reward: 88.323\n",
      "Total T: 107372 Episode Num: 277 Episode T: 155 Reward: 88.228\n",
      "Total T: 107603 Episode Num: 278 Episode T: 231 Reward: 81.634\n",
      "Total T: 107777 Episode Num: 279 Episode T: 174 Reward: 86.143\n",
      "Total T: 108008 Episode Num: 280 Episode T: 231 Reward: 81.752\n",
      "Total T: 108241 Episode Num: 281 Episode T: 233 Reward: 82.004\n",
      "Total T: 108408 Episode Num: 282 Episode T: 167 Reward: 87.366\n",
      "Total T: 108730 Episode Num: 283 Episode T: 322 Reward: 76.057\n",
      "Total T: 108952 Episode Num: 284 Episode T: 222 Reward: 82.320\n",
      "Total T: 109107 Episode Num: 285 Episode T: 155 Reward: 87.873\n",
      "Total T: 109267 Episode Num: 286 Episode T: 160 Reward: 87.641\n",
      "Total T: 109487 Episode Num: 287 Episode T: 220 Reward: 84.231\n",
      "Total T: 109720 Episode Num: 288 Episode T: 233 Reward: 82.961\n",
      "Total T: 109951 Episode Num: 289 Episode T: 231 Reward: 83.221\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.301\n",
      "---------------------------------------\n",
      "Total T: 110177 Episode Num: 290 Episode T: 226 Reward: 81.368\n",
      "Total T: 110391 Episode Num: 291 Episode T: 214 Reward: 83.389\n",
      "Total T: 110716 Episode Num: 292 Episode T: 325 Reward: 74.930\n",
      "Total T: 110866 Episode Num: 293 Episode T: 150 Reward: 88.211\n",
      "Total T: 111139 Episode Num: 294 Episode T: 273 Reward: 80.600\n",
      "Total T: 111306 Episode Num: 295 Episode T: 167 Reward: 88.334\n",
      "Total T: 111517 Episode Num: 296 Episode T: 211 Reward: 83.738\n",
      "Total T: 111817 Episode Num: 297 Episode T: 300 Reward: 78.220\n",
      "Total T: 111974 Episode Num: 298 Episode T: 157 Reward: 88.359\n",
      "Total T: 112184 Episode Num: 299 Episode T: 210 Reward: 84.248\n",
      "Total T: 112348 Episode Num: 300 Episode T: 164 Reward: 87.846\n",
      "Total T: 112506 Episode Num: 301 Episode T: 158 Reward: 88.966\n",
      "Total T: 112651 Episode Num: 302 Episode T: 145 Reward: 88.357\n",
      "Total T: 112933 Episode Num: 303 Episode T: 282 Reward: 78.812\n",
      "Total T: 113082 Episode Num: 304 Episode T: 149 Reward: 88.023\n",
      "Total T: 113248 Episode Num: 305 Episode T: 166 Reward: 87.574\n",
      "Total T: 113475 Episode Num: 306 Episode T: 227 Reward: 82.553\n",
      "Total T: 113761 Episode Num: 307 Episode T: 286 Reward: 78.224\n",
      "Total T: 113990 Episode Num: 308 Episode T: 229 Reward: 83.387\n",
      "Total T: 114147 Episode Num: 309 Episode T: 157 Reward: 87.984\n",
      "Total T: 114287 Episode Num: 310 Episode T: 140 Reward: 88.743\n",
      "Total T: 114521 Episode Num: 311 Episode T: 234 Reward: 81.602\n",
      "Total T: 114835 Episode Num: 312 Episode T: 314 Reward: 76.017\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.277\n",
      "---------------------------------------\n",
      "Total T: 115062 Episode Num: 313 Episode T: 227 Reward: 82.708\n",
      "Total T: 115234 Episode Num: 314 Episode T: 172 Reward: 86.101\n",
      "Total T: 115471 Episode Num: 315 Episode T: 237 Reward: 81.222\n",
      "Total T: 115693 Episode Num: 316 Episode T: 222 Reward: 82.786\n",
      "Total T: 115956 Episode Num: 317 Episode T: 263 Reward: 79.347\n",
      "Total T: 116308 Episode Num: 318 Episode T: 352 Reward: 72.543\n",
      "Total T: 116528 Episode Num: 319 Episode T: 220 Reward: 83.721\n",
      "Total T: 116682 Episode Num: 320 Episode T: 154 Reward: 88.679\n",
      "Total T: 116925 Episode Num: 321 Episode T: 243 Reward: 81.332\n",
      "Total T: 117103 Episode Num: 322 Episode T: 178 Reward: 86.401\n",
      "Total T: 117311 Episode Num: 323 Episode T: 208 Reward: 83.872\n",
      "Total T: 117527 Episode Num: 324 Episode T: 216 Reward: 83.259\n",
      "Total T: 117684 Episode Num: 325 Episode T: 157 Reward: 87.858\n",
      "Total T: 117956 Episode Num: 326 Episode T: 272 Reward: 79.068\n",
      "Total T: 118243 Episode Num: 327 Episode T: 287 Reward: 77.847\n",
      "Total T: 118398 Episode Num: 328 Episode T: 155 Reward: 86.939\n",
      "Total T: 118615 Episode Num: 329 Episode T: 217 Reward: 83.351\n",
      "Total T: 118854 Episode Num: 330 Episode T: 239 Reward: 81.212\n",
      "Total T: 119024 Episode Num: 331 Episode T: 170 Reward: 88.004\n",
      "Total T: 119330 Episode Num: 332 Episode T: 306 Reward: 75.958\n",
      "Total T: 119497 Episode Num: 333 Episode T: 167 Reward: 86.390\n",
      "Total T: 119845 Episode Num: 334 Episode T: 348 Reward: 73.666\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.367\n",
      "---------------------------------------\n",
      "Total T: 120183 Episode Num: 335 Episode T: 338 Reward: 74.158\n",
      "Total T: 120335 Episode Num: 336 Episode T: 152 Reward: 88.120\n",
      "Total T: 120561 Episode Num: 337 Episode T: 226 Reward: 81.916\n",
      "Total T: 120851 Episode Num: 338 Episode T: 290 Reward: 77.761\n",
      "Total T: 121227 Episode Num: 339 Episode T: 376 Reward: 71.041\n",
      "Total T: 121582 Episode Num: 340 Episode T: 355 Reward: 72.231\n",
      "Total T: 121953 Episode Num: 341 Episode T: 371 Reward: 71.703\n",
      "Total T: 122095 Episode Num: 342 Episode T: 142 Reward: 88.914\n",
      "Total T: 122245 Episode Num: 343 Episode T: 150 Reward: 88.558\n",
      "Total T: 122470 Episode Num: 344 Episode T: 225 Reward: 81.796\n",
      "Total T: 122785 Episode Num: 345 Episode T: 315 Reward: 76.271\n",
      "Total T: 122982 Episode Num: 346 Episode T: 197 Reward: 85.278\n",
      "Total T: 123240 Episode Num: 347 Episode T: 258 Reward: 80.205\n",
      "Total T: 123677 Episode Num: 348 Episode T: 437 Reward: 66.540\n",
      "Total T: 123903 Episode Num: 349 Episode T: 226 Reward: 83.026\n",
      "Total T: 124093 Episode Num: 350 Episode T: 190 Reward: 85.018\n",
      "Total T: 124325 Episode Num: 351 Episode T: 232 Reward: 82.481\n",
      "Total T: 124555 Episode Num: 352 Episode T: 230 Reward: 82.554\n",
      "Total T: 124825 Episode Num: 353 Episode T: 270 Reward: 80.131\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.372\n",
      "---------------------------------------\n",
      "Total T: 125228 Episode Num: 354 Episode T: 403 Reward: 69.496\n",
      "Total T: 125461 Episode Num: 355 Episode T: 233 Reward: 82.456\n",
      "Total T: 125858 Episode Num: 356 Episode T: 397 Reward: 69.825\n",
      "Total T: 126071 Episode Num: 357 Episode T: 213 Reward: 83.431\n",
      "Total T: 126324 Episode Num: 358 Episode T: 253 Reward: 81.016\n",
      "Total T: 126507 Episode Num: 359 Episode T: 183 Reward: 86.245\n",
      "Total T: 126995 Episode Num: 360 Episode T: 488 Reward: 62.400\n",
      "Total T: 127210 Episode Num: 361 Episode T: 215 Reward: 83.421\n",
      "Total T: 127367 Episode Num: 362 Episode T: 157 Reward: 88.104\n",
      "Total T: 127727 Episode Num: 363 Episode T: 360 Reward: 72.191\n",
      "Total T: 128271 Episode Num: 364 Episode T: 544 Reward: 58.847\n",
      "Total T: 128502 Episode Num: 365 Episode T: 231 Reward: 82.621\n",
      "Total T: 128846 Episode Num: 366 Episode T: 344 Reward: 73.720\n",
      "Total T: 129008 Episode Num: 367 Episode T: 162 Reward: 87.502\n",
      "Total T: 129320 Episode Num: 368 Episode T: 312 Reward: 74.497\n",
      "Total T: 129478 Episode Num: 369 Episode T: 158 Reward: 88.369\n",
      "Total T: 129739 Episode Num: 370 Episode T: 261 Reward: 79.744\n",
      "Total T: 129973 Episode Num: 371 Episode T: 234 Reward: 81.343\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.357\n",
      "---------------------------------------\n",
      "Total T: 130127 Episode Num: 372 Episode T: 154 Reward: 88.500\n",
      "Total T: 130743 Episode Num: 373 Episode T: 616 Reward: 52.514\n",
      "Total T: 131061 Episode Num: 374 Episode T: 318 Reward: 74.663\n",
      "Total T: 131291 Episode Num: 375 Episode T: 230 Reward: 82.724\n",
      "Total T: 131446 Episode Num: 376 Episode T: 155 Reward: 87.856\n",
      "Total T: 131655 Episode Num: 377 Episode T: 209 Reward: 83.852\n",
      "Total T: 131876 Episode Num: 378 Episode T: 221 Reward: 82.459\n",
      "Total T: 132090 Episode Num: 379 Episode T: 214 Reward: 83.997\n",
      "Total T: 132302 Episode Num: 380 Episode T: 212 Reward: 83.229\n",
      "Total T: 132542 Episode Num: 381 Episode T: 240 Reward: 80.873\n",
      "Total T: 132848 Episode Num: 382 Episode T: 306 Reward: 77.467\n",
      "Total T: 133073 Episode Num: 383 Episode T: 225 Reward: 83.341\n",
      "Total T: 133283 Episode Num: 384 Episode T: 210 Reward: 82.933\n",
      "Total T: 133502 Episode Num: 385 Episode T: 219 Reward: 83.871\n",
      "Total T: 133726 Episode Num: 386 Episode T: 224 Reward: 82.754\n",
      "Total T: 133875 Episode Num: 387 Episode T: 149 Reward: 88.185\n",
      "Total T: 134208 Episode Num: 388 Episode T: 333 Reward: 74.366\n",
      "Total T: 134444 Episode Num: 389 Episode T: 236 Reward: 82.389\n",
      "Total T: 134673 Episode Num: 390 Episode T: 229 Reward: 82.078\n",
      "Total T: 134902 Episode Num: 391 Episode T: 229 Reward: 82.599\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.360\n",
      "---------------------------------------\n",
      "Total T: 135231 Episode Num: 392 Episode T: 329 Reward: 74.835\n",
      "Total T: 135460 Episode Num: 393 Episode T: 229 Reward: 83.027\n",
      "Total T: 135688 Episode Num: 394 Episode T: 228 Reward: 82.746\n",
      "Total T: 135911 Episode Num: 395 Episode T: 223 Reward: 81.714\n",
      "Total T: 136124 Episode Num: 396 Episode T: 213 Reward: 83.780\n",
      "Total T: 136508 Episode Num: 397 Episode T: 384 Reward: 69.696\n",
      "Total T: 136812 Episode Num: 398 Episode T: 304 Reward: 75.965\n",
      "Total T: 137025 Episode Num: 399 Episode T: 213 Reward: 83.758\n",
      "Total T: 137202 Episode Num: 400 Episode T: 177 Reward: 86.039\n",
      "Total T: 137504 Episode Num: 401 Episode T: 302 Reward: 76.575\n",
      "Total T: 137718 Episode Num: 402 Episode T: 214 Reward: 83.098\n",
      "Total T: 137971 Episode Num: 403 Episode T: 253 Reward: 81.094\n",
      "Total T: 138223 Episode Num: 404 Episode T: 252 Reward: 80.863\n",
      "Total T: 138576 Episode Num: 405 Episode T: 353 Reward: 73.034\n",
      "Total T: 138878 Episode Num: 406 Episode T: 302 Reward: 75.497\n",
      "Total T: 139157 Episode Num: 407 Episode T: 279 Reward: 78.384\n",
      "Total T: 139411 Episode Num: 408 Episode T: 254 Reward: 80.053\n",
      "Total T: 139644 Episode Num: 409 Episode T: 233 Reward: 82.363\n",
      "Total T: 139934 Episode Num: 410 Episode T: 290 Reward: 77.993\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.376\n",
      "---------------------------------------\n",
      "Total T: 140220 Episode Num: 411 Episode T: 286 Reward: 77.429\n",
      "Total T: 140456 Episode Num: 412 Episode T: 236 Reward: 81.939\n",
      "Total T: 140606 Episode Num: 413 Episode T: 150 Reward: 88.085\n",
      "Total T: 140935 Episode Num: 414 Episode T: 329 Reward: 74.840\n",
      "Total T: 141168 Episode Num: 415 Episode T: 233 Reward: 82.375\n",
      "Total T: 141408 Episode Num: 416 Episode T: 240 Reward: 81.056\n",
      "Total T: 141629 Episode Num: 417 Episode T: 221 Reward: 82.533\n",
      "Total T: 141778 Episode Num: 418 Episode T: 149 Reward: 88.103\n",
      "Total T: 141940 Episode Num: 419 Episode T: 162 Reward: 87.748\n",
      "Total T: 142242 Episode Num: 420 Episode T: 302 Reward: 75.943\n",
      "Total T: 142473 Episode Num: 421 Episode T: 231 Reward: 82.076\n",
      "Total T: 142764 Episode Num: 422 Episode T: 291 Reward: 78.227\n",
      "Total T: 142918 Episode Num: 423 Episode T: 154 Reward: 88.461\n",
      "Total T: 143224 Episode Num: 424 Episode T: 306 Reward: 77.415\n",
      "Total T: 143384 Episode Num: 425 Episode T: 160 Reward: 88.692\n",
      "Total T: 143552 Episode Num: 426 Episode T: 168 Reward: 86.845\n",
      "Total T: 143712 Episode Num: 427 Episode T: 160 Reward: 86.937\n",
      "Total T: 143863 Episode Num: 428 Episode T: 151 Reward: 88.297\n",
      "Total T: 144118 Episode Num: 429 Episode T: 255 Reward: 80.506\n",
      "Total T: 144354 Episode Num: 430 Episode T: 236 Reward: 81.309\n",
      "Total T: 144570 Episode Num: 431 Episode T: 216 Reward: 83.018\n",
      "Total T: 144912 Episode Num: 432 Episode T: 342 Reward: 73.393\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.379\n",
      "---------------------------------------\n",
      "Total T: 145217 Episode Num: 433 Episode T: 305 Reward: 76.641\n",
      "Total T: 145381 Episode Num: 434 Episode T: 164 Reward: 86.692\n",
      "Total T: 145595 Episode Num: 435 Episode T: 214 Reward: 83.102\n",
      "Total T: 145817 Episode Num: 436 Episode T: 222 Reward: 83.315\n",
      "Total T: 146034 Episode Num: 437 Episode T: 217 Reward: 82.948\n",
      "Total T: 146191 Episode Num: 438 Episode T: 157 Reward: 88.079\n",
      "Total T: 146338 Episode Num: 439 Episode T: 147 Reward: 88.068\n",
      "Total T: 146559 Episode Num: 440 Episode T: 221 Reward: 83.619\n",
      "Total T: 146790 Episode Num: 441 Episode T: 231 Reward: 82.816\n",
      "Total T: 147109 Episode Num: 442 Episode T: 319 Reward: 74.599\n",
      "Total T: 147258 Episode Num: 443 Episode T: 149 Reward: 88.886\n",
      "Total T: 147524 Episode Num: 444 Episode T: 266 Reward: 79.471\n",
      "Total T: 147737 Episode Num: 445 Episode T: 213 Reward: 83.607\n",
      "Total T: 147961 Episode Num: 446 Episode T: 224 Reward: 83.164\n",
      "Total T: 148111 Episode Num: 447 Episode T: 150 Reward: 88.367\n",
      "Total T: 148465 Episode Num: 448 Episode T: 354 Reward: 72.433\n",
      "Total T: 148703 Episode Num: 449 Episode T: 238 Reward: 81.683\n",
      "Total T: 148944 Episode Num: 450 Episode T: 241 Reward: 80.393\n",
      "Total T: 149135 Episode Num: 451 Episode T: 191 Reward: 85.303\n",
      "Total T: 149287 Episode Num: 452 Episode T: 152 Reward: 87.779\n",
      "Total T: 149444 Episode Num: 453 Episode T: 157 Reward: 87.200\n",
      "Total T: 149665 Episode Num: 454 Episode T: 221 Reward: 82.162\n",
      "Total T: 149893 Episode Num: 455 Episode T: 228 Reward: 82.041\n",
      "---------------------------------------\n",
      "Evaluation over 10 episodes: 93.367\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# MAIN FILE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Runs policy for X episodes and returns average reward\n",
    "# A fixed seed is used for the eval environment\n",
    "def eval_policy(policy, env_name, seed, eval_episodes=10):\n",
    "\teval_env = gym.make(env_name)\n",
    "\teval_env.seed(seed + 100)\n",
    "\n",
    "\tavg_reward = 0.\n",
    "\tfor _ in range(eval_episodes):\n",
    "\t\tstate, done = eval_env.reset(), False\n",
    "\t\twhile not done:\n",
    "\t\t\taction = policy.select_action(np.array(state))\n",
    "\t\t\tstate, reward, done, _ = eval_env.step(action)\n",
    "\t\t\tavg_reward += reward\n",
    "\n",
    "\tavg_reward /= eval_episodes\n",
    "\n",
    "\tprint(\"---------------------------------------\")\n",
    "\tprint(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "\tprint(\"---------------------------------------\")\n",
    "\treturn avg_reward\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\t\n",
    "\t'''\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\tparser.add_argument(\"--policy\", default=\"TD3\")                  # Policy name (TD3, DDPG or OurDDPG)\n",
    "\tparser.add_argument(\"--env\", default=\"HalfCheetah-v2\")          # OpenAI gym environment name\n",
    "\tparser.add_argument(\"--seed\", default=0, type=int)              # Sets Gym, PyTorch and Numpy seeds\n",
    "\tparser.add_argument(\"--start_timesteps\", default=25e3, type=int)# Time steps initial random policy is used\n",
    "\tparser.add_argument(\"--eval_freq\", default=5e3, type=int)       # How often (time steps) we evaluate\n",
    "\tparser.add_argument(\"--max_timesteps\", default=1e6, type=int)   # Max time steps to run environment\n",
    "\tparser.add_argument(\"--expl_noise\", default=0.1, type=float)    # Std of Gaussian exploration noise\n",
    "\tparser.add_argument(\"--batch_size\", default=256, type=int)      # Batch size for both actor and critic\n",
    "\tparser.add_argument(\"--discount\", default=0.99, type=float)     # Discount factor\n",
    "\tparser.add_argument(\"--tau\", default=0.005, type=float)         # Target network update rate\n",
    "\tparser.add_argument(\"--policy_noise\", default=0.2)              # Noise added to target policy during critic update\n",
    "\tparser.add_argument(\"--noise_clip\", default=0.5)                # Range to clip target policy noise\n",
    "\tparser.add_argument(\"--policy_freq\", default=2, type=int)       # Frequency of delayed policy updates\n",
    "\tparser.add_argument(\"--save_model\", action=\"store_true\")        # Save model and optimizer parameters\n",
    "\tparser.add_argument(\"--load_model\", default=\"\")                 # Model load file name, \"\" doesn't load, \"default\" uses file_name\n",
    "\targs = parser.parse_args()\n",
    "\t'''\n",
    "\targs = Args()\n",
    "\n",
    "\tfile_name = f\"{args.policy}_{args.env}_{args.seed}\"\n",
    "\tprint(\"---------------------------------------\")\n",
    "\tprint(f\"Policy: {args.policy}, Env: {args.env}, Seed: {args.seed}\")\n",
    "\tprint(\"---------------------------------------\")\n",
    "\n",
    "\tif not os.path.exists(\"./results\"):\n",
    "\t\tos.makedirs(\"./results\")\n",
    "\n",
    "\tif args.save_model and not os.path.exists(\"./models\"):\n",
    "\t\tos.makedirs(\"./models\")\n",
    "\n",
    "\tenv = gym.make(args.env)\n",
    "\n",
    "\t# Set seeds\n",
    "\tenv.seed(args.seed)\n",
    "\tenv.action_space.seed(args.seed)\n",
    "\ttorch.manual_seed(args.seed)\n",
    "\tnp.random.seed(args.seed)\n",
    "\t\n",
    "\tstate_dim = env.observation_space.shape[0]\n",
    "\taction_dim = env.action_space.shape[0] \n",
    "\tmax_action = float(env.action_space.high[0])\n",
    "\n",
    "\tkwargs = {\n",
    "\t\t\"state_dim\": state_dim,\n",
    "\t\t\"action_dim\": action_dim,\n",
    "\t\t\"max_action\": max_action,\n",
    "\t\t\"discount\": args.discount,\n",
    "\t\t\"tau\": args.tau,\n",
    "\t}\n",
    "\n",
    "\t# Initialize policy\n",
    "\tif args.policy == \"TD3\":\n",
    "\t\t# Target policy smoothing is scaled wrt the action scale\n",
    "\t\tkwargs[\"policy_noise\"] = args.policy_noise * max_action\n",
    "\t\tkwargs[\"noise_clip\"] = args.noise_clip * max_action\n",
    "\t\tkwargs[\"policy_freq\"] = args.policy_freq\n",
    "\t\t#policy = TD3.TD3(**kwargs)\n",
    "\t\tpolicy = TD3(**kwargs)\n",
    "\telif args.policy == \"OurDDPG\":\n",
    "\t\tpolicy = OurDDPG.DDPG(**kwargs)\n",
    "\telif args.policy == \"DDPG\":\n",
    "\t\tpolicy = DDPG.DDPG(**kwargs)\n",
    "\n",
    "\tif args.load_model != \"\":\n",
    "\t\tpolicy_file = file_name if args.load_model == \"default\" else args.load_model\n",
    "\t\tpolicy.load(f\"./models/{policy_file}\")\n",
    "\n",
    "\treplay_buffer = utils.ReplayBuffer(state_dim, action_dim)\n",
    "\t\n",
    "\t# Evaluate untrained policy\n",
    "\tevaluations = [eval_policy(policy, args.env, args.seed)]\n",
    "\n",
    "\tstate, done = env.reset(), False\n",
    "\tepisode_reward = 0\n",
    "\tepisode_timesteps = 0\n",
    "\tepisode_num = 0\n",
    "\n",
    "\tfor t in range(int(args.max_timesteps)):\n",
    "\t\t\n",
    "\t\tepisode_timesteps += 1\n",
    "\n",
    "\t\t# Select action randomly or according to policy\n",
    "\t\tif t < args.start_timesteps:\n",
    "\t\t\taction = env.action_space.sample()\n",
    "\t\telse:\n",
    "\t\t\taction = (\n",
    "\t\t\t\tpolicy.select_action(np.array(state))\n",
    "\t\t\t\t+ np.random.normal(0, max_action * args.expl_noise, size=action_dim)\n",
    "\t\t\t).clip(-max_action, max_action)\n",
    "\n",
    "\t\t# Perform action\n",
    "\t\tnext_state, reward, done, _ = env.step(action) \n",
    "\t\tdone_bool = float(done) if episode_timesteps < env._max_episode_steps else 0\n",
    "\n",
    "\t\t# Store data in replay buffer\n",
    "\t\treplay_buffer.add(state, action, next_state, reward, done_bool)\n",
    "\n",
    "\t\tstate = next_state\n",
    "\t\tepisode_reward += reward\n",
    "\n",
    "\t\t# Train agent after collecting sufficient data\n",
    "\t\tif t >= args.start_timesteps:\n",
    "\t\t\tpolicy.train(replay_buffer, args.batch_size)\n",
    "\n",
    "\t\tif done: \n",
    "\t\t\t# +1 to account for 0 indexing. +0 on ep_timesteps since it will increment +1 even if done=True\n",
    "\t\t\tprint(f\"Total T: {t+1} Episode Num: {episode_num+1} Episode T: {episode_timesteps} Reward: {episode_reward:.3f}\")\n",
    "\t\t\t# Reset environment\n",
    "\t\t\tstate, done = env.reset(), False\n",
    "\t\t\tepisode_reward = 0\n",
    "\t\t\tepisode_timesteps = 0\n",
    "\t\t\tepisode_num += 1 \n",
    "\n",
    "\t\t# Evaluate episode\n",
    "\t\tif (t + 1) % args.eval_freq == 0:\n",
    "\t\t\tevaluations.append(eval_policy(policy, args.env, args.seed))\n",
    "\t\t\tnp.save(f\"./results/{file_name}\", evaluations)\n",
    "\t\t\tif args.save_model: policy.save(f\"./models/{file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.ReplayBuffer at 0x1b47c7e1a50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HanaCatic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\HanaCatic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\HanaCatic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# Visualization\n",
    "\n",
    "env.close()\n",
    "# Assuming 'device' and 'act' are defined elsewhere in your script\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the continuous version of the Mountain Car environment\n",
    "env = gym.make(\"MountainCarContinuous-v0\", render_mode=\"human\")\n",
    "\n",
    "# Reset the environment and prepare the initial state\n",
    "state, done = env.reset(), False\n",
    "state = torch.tensor(state, device=device).float().unsqueeze(0)\n",
    "\n",
    "# Initialize variables to track episodes and scores\n",
    "ep_count = 0\n",
    "current_ep_reward = 0\n",
    "scores = []\n",
    "\n",
    "# Run simulation for 50 episodes\n",
    "while ep_count < 50:\n",
    "    env.render()\n",
    "    action = policy.select_action(np.array(state))  # Ensure this function now returns a continuous action\n",
    "    state, reward, done, _ = env.step([action.item()])  # Execute action, note the list around action.item()\n",
    "\n",
    "    state = torch.tensor(state, device=device).float().unsqueeze(0)\n",
    "    current_ep_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        ep_count += 1\n",
    "        scores.append(current_ep_reward)\n",
    "        current_ep_reward = 0\n",
    "        state, done = env.reset(), False  # Reset for the next episode\n",
    "        state = torch.tensor(state, device=device).float().unsqueeze(0)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
